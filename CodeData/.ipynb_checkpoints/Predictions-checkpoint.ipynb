{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from trackml.dataset import load_event, load_dataset\n",
    "from trackml.score import score_event\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler, Normalizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy import spatial\n",
    "\n",
    "# Change this according to your directory preferred setting\n",
    "path_to_train = \"../train_sample/train_100_events\"\n",
    "\n",
    "#plotdata for end\n",
    "plotdata = []\n",
    "plotnames = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "event_prefix = \"event000001000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits, cells, particles, truth = load_event(os.path.join(path_to_train, event_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "class Clusterer(object):\n",
    "    \n",
    "    def __init__(self, eps):\n",
    "        self.eps = eps\n",
    "        \n",
    "    \n",
    "    def _preprocess(self, hits):\n",
    "        \n",
    "        x = hits.x.values\n",
    "        y = hits.y.values\n",
    "        z = hits.z.values\n",
    "\n",
    "        r = np.sqrt(x**2 + y**2 + z**2)\n",
    "        hits['x2'] = x/r\n",
    "        hits['y2'] = y/r\n",
    "\n",
    "        r = np.sqrt(x**2 + y**2)\n",
    "        hits['z2'] = z/r\n",
    "\n",
    "        ss = StandardScaler()\n",
    "        X = ss.fit_transform(hits[['x2', 'y2', 'z2']].values)\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    \n",
    "    def predict(self, hits):\n",
    "        \n",
    "        X = self._preprocess(hits)\n",
    "        \n",
    "        cl = DBSCAN(eps=self.eps, min_samples=1, algorithm='kd_tree')\n",
    "        labels = cl.fit_predict(X)\n",
    "        \n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Clusterer(eps=0.008)\n",
    "labels = model.predict(hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_one_event_submission(event_id, hits, labels):\n",
    "    sub_data = np.column_stack(([event_id]*len(hits), hits.hit_id.values, labels))\n",
    "    submission = pd.DataFrame(data=sub_data, columns=[\"event_id\", \"hit_id\", \"track_id\"]).astype(int)\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = create_one_event_submission(0, hits, labels)\n",
    "score = score_event(truth, submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Your score: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dataset(path_to_train, skip=1000, nevents=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_submissions = []\n",
    "dataset_scores = []\n",
    "\n",
    "for event_id, hits, cells, particles, truth in load_dataset(path_to_train, skip=0, nevents=5):\n",
    "        \n",
    "    # Track pattern recognition\n",
    "    model = Clusterer(eps=0.008)\n",
    "    labels = model.predict(hits)\n",
    "        \n",
    "    # Prepare submission for an event\n",
    "    one_submission = create_one_event_submission(event_id, hits, labels)\n",
    "    dataset_submissions.append(one_submission)\n",
    "    \n",
    "    # Score for the event\n",
    "    score = score_event(truth, one_submission)\n",
    "    dataset_scores.append(score)\n",
    "    \n",
    "    print(\"Score for event %d: %.3f\" % (event_id, score))\n",
    "    \n",
    "print('Mean score: %.3f' % (np.mean(dataset_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for arranging hits in a track (closest to origin, closest track to previous track, and so on...)\n",
    "def arrange_track(track_points):\n",
    "    arranged_track = pd.DataFrame()\n",
    "\n",
    "    pt = [0, 0, 0]\n",
    "    kdtree = spatial.KDTree(track_points)\n",
    "    distance, index = kdtree.query(pt)\n",
    "\n",
    "    arranged_track = arranged_track.append(track_points.iloc[index])\n",
    "    track_points = track_points.drop(track_points.index[index]).reset_index(drop=True)\n",
    "\n",
    "    while not track_points.empty:\n",
    "        pt = arranged_track.iloc[-1]\n",
    "        kdtree = spatial.KDTree(track_points)\n",
    "        distance, index = kdtree.query(pt)\n",
    "\n",
    "        arranged_track = arranged_track.append(track_points.iloc[index])\n",
    "        track_points = track_points.drop(track_points.index[index]).reset_index(drop=True)\n",
    "        \n",
    "    return arranged_track\n",
    "\n",
    "test_points = pd.DataFrame([[0, 0, 5], [0, 0, 1], [0, 0, 3], [0, 0, 2]])\n",
    "arrange_track(test_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN benchmark preprocessing / coordinate transformation\n",
    "x = hits.x.values\n",
    "y = hits.y.values\n",
    "z = hits.z.values\n",
    "\n",
    "r = np.sqrt(x**2 + y**2 + z**2)\n",
    "hits['x2'] = x/r\n",
    "hits['y2'] = y/r\n",
    "\n",
    "r = np.sqrt(x**2 + y**2)\n",
    "hits['z2'] = z/r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = truth.particle_id.unique()[1::500]\n",
    "fig = plt.figure(figsize=(20,7))\n",
    "\n",
    "ax = fig.add_subplot(121,projection='3d')\n",
    "for track in tracks:\n",
    "    hit_ids = truth[truth['particle_id'] == track]['hit_id']\n",
    "    t = hits[hits['hit_id'].isin(hit_ids)][['x2', 'y2', 'z2']]\n",
    "    ax.plot3D(t.z2, t.x2, t.y2, '.', ms=10)\n",
    "    \n",
    "ax.set_xlabel('z2')\n",
    "ax.set_ylabel('x2')\n",
    "ax.set_zlabel('y2')\n",
    "ax.set_title(\"True Tracks (Scatter Plot)\", y=-.15, size=20)\n",
    "\n",
    "ax2 = fig.add_subplot(122,projection='3d')\n",
    "for track in tracks:\n",
    "    hit_ids = truth[truth['particle_id'] == track]['hit_id']\n",
    "    t = hits[hits['hit_id'].isin(hit_ids)][['x2', 'y2', 'z2']]\n",
    "    t = arrange_track(t)\n",
    "    ax2.plot3D(t.z2, t.x2, t.y2, '.-', ms=10)\n",
    "    \n",
    "ax2.set_xlabel('z2')\n",
    "ax2.set_ylabel('x2')\n",
    "ax2.set_zlabel('y2')\n",
    "ax2.set_title(\"True Tracks (Line Plot)\", y=-.15, size=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hits[['x2', 'y2', 'z2']]\n",
    "scaler = StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "eps = 0.008\n",
    "min_samp = 1\n",
    "db = DBSCAN(eps=eps, min_samples=min_samp, metric='euclidean').fit(X)\n",
    "labels = db.labels_\n",
    "\n",
    "clustering = pd.DataFrame()\n",
    "clustering['hit_id'] = truth['hit_id']\n",
    "clustering['track_id'] = labels\n",
    "\n",
    "score = score_event(truth, clustering)\n",
    "print('track-ml custom metric score:', round(score, 4))\n",
    "\n",
    "labels_true = truth['particle_id']\n",
    "n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "\n",
    "print('\\nOTHER CLUSTERING RESULTS:')\n",
    "print('Estimated number of clusters: %d' % n_clusters)\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels_true, labels))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels_true, labels))\n",
    "print(\"Adjusted Rand Index: %0.3f\" % metrics.adjusted_rand_score(labels_true, labels))\n",
    "rej_perc = list(labels).count(-1) / float(hits.shape[0]) * 100\n",
    "rej_perc = round(rej_perc, 2)\n",
    "print (\"Rejected samples %:\", str(rej_perc) + '%')\n",
    "rejected_count = list(labels).count(-1)\n",
    "print (\"Rejected samples:\", rejected_count)\n",
    "print (\"Total samples:\", hits.shape[0])\n",
    "print (\"Clustered samples:\", hits.shape[0] - list(labels).count(-1))\n",
    "\n",
    "plotdata.append[score]\n",
    "plotname.append[\"DBSCANbaseline\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = truth.particle_id.unique()[1::100]\n",
    "fig = plt.figure(figsize=(20,7))\n",
    "\n",
    "ax = fig.add_subplot(121,projection='3d')\n",
    "\n",
    "tracks_hit_ids = truth[truth['particle_id'].isin(tracks)]['hit_id'] # all hits in tracks\n",
    "clusters = clustering[clustering['hit_id'].isin(tracks_hit_ids)].track_id.unique() # all clusters containing the hits in tracks\n",
    "for cluster in clusters:\n",
    "    cluster_hit_ids = clustering[clustering['track_id'] == cluster]['hit_id'] # all hits in cluster\n",
    "    plot_hit_ids = list(set(tracks_hit_ids) & set(cluster_hit_ids))\n",
    "    t = hits[hits['hit_id'].isin(plot_hit_ids)][['x2', 'y2', 'z2']]\n",
    "    if cluster == -1:\n",
    "        ax.plot3D(t.z2, t.x2, t.y2, '.', ms=10, color='black')\n",
    "    else:\n",
    "        ax.plot3D(t.z2, t.x2, t.y2, '.-', ms=10)\n",
    "    \n",
    "ax.set_xlabel('z2')\n",
    "ax.set_ylabel('x2')\n",
    "ax.set_zlabel('y2')\n",
    "ax.set_title('Clustered Hits (Predicted Tracks)', y=-.15, size=20)\n",
    "\n",
    "ax2 = fig.add_subplot(122,projection='3d')\n",
    "for track in tracks:\n",
    "    hit_ids = truth[truth['particle_id'] == track]['hit_id']\n",
    "    t = hits[hits['hit_id'].isin(hit_ids)][['x2', 'y2', 'z2']]\n",
    "    t = arrange_track(t)\n",
    "    ax2.plot3D(t.z2, t.x2, t.y2, '.-', ms=10)\n",
    "    \n",
    "ax2.set_xlabel('z2')\n",
    "ax2.set_ylabel('x2')\n",
    "ax2.set_zlabel('y2')\n",
    "ax2.set_title('True Tracks', y=-.15, size=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = truth.particle_id.unique()[1::100]\n",
    "fig = plt.figure(figsize=(20,7))\n",
    "\n",
    "ax = fig.add_subplot(121,projection='3d')\n",
    "\n",
    "tracks_hit_ids = truth[truth['particle_id'].isin(tracks)]['hit_id'] # all hits in tracks\n",
    "clusters = clustering[clustering['hit_id'].isin(tracks_hit_ids)].track_id.unique() # all clusters containing the hits in tracks\n",
    "for cluster in clusters:\n",
    "    cluster_hit_ids = clustering[clustering['track_id'] == cluster]['hit_id'] # all hits in cluster\n",
    "    plot_hit_ids = list(set(tracks_hit_ids) & set(cluster_hit_ids))\n",
    "    t = hits[hits['hit_id'].isin(plot_hit_ids)][['x', 'y', 'z']]\n",
    "    if cluster == -1:\n",
    "        ax.plot3D(t.z, t.x, t.y, '.', ms=10, color='black')\n",
    "    else:\n",
    "        ax.plot3D(t.z, t.x, t.y, '.-', ms=10)\n",
    "    \n",
    "ax.set_xlabel('z (mm)')\n",
    "ax.set_ylabel('x (mm)')\n",
    "ax.set_zlabel('y (mm)')\n",
    "ax.set_title('Clustered Hits (Predicted Tracks)', y=-.15, size=20)\n",
    "\n",
    "ax2 = fig.add_subplot(122,projection='3d')\n",
    "for track in tracks:\n",
    "    hit_ids = truth[truth['particle_id'] == track]['hit_id']\n",
    "    t = hits[hits['hit_id'].isin(hit_ids)][['x', 'y', 'z']]\n",
    "    t = arrange_track(t)\n",
    "    ax2.plot3D(t.z, t.x, t.y, '.-', ms=10)\n",
    "    \n",
    "ax2.set_xlabel('z (mm)')\n",
    "ax2.set_ylabel('x (mm)')\n",
    "ax2.set_zlabel('y (mm)')\n",
    "ax2.set_title('True Tracks', y=-.15, size=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here I try with a higher eps (eps=0.018)\n",
    "#Increasing the eps means decreasing the density required to form a cluster. \n",
    "#eps is the distance that is used to define the neighbors of a sample. \n",
    "#Since we increased eps, we expect bigger clusters to be formed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hits[['x2', 'y2', 'z2']]\n",
    "scaler = StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "eps = 0.018\n",
    "min_samp = 1\n",
    "db = DBSCAN(eps=eps, min_samples=min_samp, metric='euclidean').fit(X)\n",
    "labels = db.labels_\n",
    "\n",
    "clustering = pd.DataFrame()\n",
    "clustering['hit_id'] = truth['hit_id']\n",
    "clustering['track_id'] = labels\n",
    "\n",
    "score = score_event(truth, clustering)\n",
    "print('track-ml custom metric score:', round(score, 4))\n",
    "\n",
    "labels_true = truth['particle_id']\n",
    "n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "\n",
    "print('\\nOTHER CLUSTERING RESULTS:')\n",
    "print('Estimated number of clusters: %d' % n_clusters)\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels_true, labels))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels_true, labels))\n",
    "print(\"Adjusted Rand Index: %0.3f\" % metrics.adjusted_rand_score(labels_true, labels))\n",
    "rej_perc = list(labels).count(-1) / float(hits.shape[0]) * 100\n",
    "rej_perc = round(rej_perc, 2)\n",
    "print (\"Rejected samples %:\", str(rej_perc) + '%')\n",
    "rejected_count = list(labels).count(-1)\n",
    "print (\"Rejected samples:\", rejected_count)\n",
    "print (\"Total samples:\", hits.shape[0])\n",
    "print (\"Clustered samples:\", hits.shape[0] - list(labels).count(-1))\n",
    "\n",
    "plotdata.append[score]\n",
    "plotname.append[\"DBSCANhigheps\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = truth.particle_id.unique()[1::100]\n",
    "fig = plt.figure(figsize=(20,7))\n",
    "\n",
    "ax = fig.add_subplot(121,projection='3d')\n",
    "\n",
    "tracks_hit_ids = truth[truth['particle_id'].isin(tracks)]['hit_id'] # all hits in tracks\n",
    "clusters = clustering[clustering['hit_id'].isin(tracks_hit_ids)].track_id.unique() # all clusters containing the hits in tracks\n",
    "for cluster in clusters:\n",
    "    cluster_hit_ids = clustering[clustering['track_id'] == cluster]['hit_id'] # all hits in cluster\n",
    "    plot_hit_ids = list(set(tracks_hit_ids) & set(cluster_hit_ids))\n",
    "    t = hits[hits['hit_id'].isin(plot_hit_ids)][['x2', 'y2', 'z2']]\n",
    "    if cluster == -1:\n",
    "        ax.plot3D(t.z2, t.x2, t.y2, '.', ms=10, color='black')\n",
    "    else:\n",
    "        ax.plot3D(t.z2, t.x2, t.y2, '.-', ms=10)\n",
    "    \n",
    "ax.set_xlabel('z2')\n",
    "ax.set_ylabel('x2')\n",
    "ax.set_zlabel('y2')\n",
    "ax.set_title('Clustered Hits (Predicted Tracks)', y=-.15, size=20)\n",
    "\n",
    "ax2 = fig.add_subplot(122,projection='3d')\n",
    "for track in tracks:\n",
    "    hit_ids = truth[truth['particle_id'] == track]['hit_id']\n",
    "    t = hits[hits['hit_id'].isin(hit_ids)][['x2', 'y2', 'z2']]\n",
    "    t = arrange_track(t)\n",
    "    ax2.plot3D(t.z2, t.x2, t.y2, '.-', ms=10)\n",
    "    \n",
    "ax2.set_xlabel('z2')\n",
    "ax2.set_ylabel('x2')\n",
    "ax2.set_zlabel('y2')\n",
    "ax2.set_title('True Tracks', y=-.15, size=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = truth.particle_id.unique()[1::100]\n",
    "fig = plt.figure(figsize=(20,7))\n",
    "\n",
    "ax = fig.add_subplot(121,projection='3d')\n",
    "\n",
    "tracks_hit_ids = truth[truth['particle_id'].isin(tracks)]['hit_id'] # all hits in tracks\n",
    "clusters = clustering[clustering['hit_id'].isin(tracks_hit_ids)].track_id.unique() # all clusters containing the hits in tracks\n",
    "for cluster in clusters:\n",
    "    cluster_hit_ids = clustering[clustering['track_id'] == cluster]['hit_id'] # all hits in cluster\n",
    "    plot_hit_ids = list(set(tracks_hit_ids) & set(cluster_hit_ids))\n",
    "    t = hits[hits['hit_id'].isin(plot_hit_ids)][['x', 'y', 'z']]\n",
    "    if cluster == -1:\n",
    "        ax.plot3D(t.z, t.x, t.y, '.', ms=10, color='black')\n",
    "    else:\n",
    "        ax.plot3D(t.z, t.x, t.y, '.-', ms=10)\n",
    "    \n",
    "ax.set_xlabel('z (mm)')\n",
    "ax.set_ylabel('x (mm)')\n",
    "ax.set_zlabel('y (mm)')\n",
    "ax.set_title('Clustered Hits (Predicted Tracks)', y=-.15, size=20)\n",
    "\n",
    "ax2 = fig.add_subplot(122,projection='3d')\n",
    "for track in tracks:\n",
    "    hit_ids = truth[truth['particle_id'] == track]['hit_id']\n",
    "    t = hits[hits['hit_id'].isin(hit_ids)][['x', 'y', 'z']]\n",
    "    t = arrange_track(t)\n",
    "    ax2.plot3D(t.z, t.x, t.y, '.-', ms=10)\n",
    "    \n",
    "ax2.set_xlabel('z (mm)')\n",
    "ax2.set_ylabel('x (mm)')\n",
    "ax2.set_zlabel('y (mm)')\n",
    "ax2.set_title('True Tracks', y=-.15, size=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now here I try with changing min_scamp=3\n",
    "#Increasing the minimum samples means decreasing the density required to form a cluster. \n",
    "#Let's see the effects of this adjustment to the score and clustering metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hits[['x2', 'y2', 'z2']]\n",
    "scaler = StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "eps = 0.008\n",
    "min_samp = 3\n",
    "db = DBSCAN(eps=eps, min_samples=min_samp, metric='euclidean').fit(X)\n",
    "labels = db.labels_\n",
    "\n",
    "clustering = pd.DataFrame()\n",
    "clustering['hit_id'] = truth['hit_id']\n",
    "clustering['track_id'] = labels\n",
    "\n",
    "score = score_event(truth, clustering)\n",
    "print('track-ml custom metric score:', round(score, 4))\n",
    "\n",
    "labels_true = truth['particle_id']\n",
    "n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "\n",
    "print('\\nOTHER CLUSTERING RESULTS:')\n",
    "print('Estimated number of clusters: %d' % n_clusters)\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels_true, labels))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels_true, labels))\n",
    "print(\"Adjusted Rand Index: %0.3f\" % metrics.adjusted_rand_score(labels_true, labels))\n",
    "rej_perc = list(labels).count(-1) / float(hits.shape[0]) * 100\n",
    "rej_perc = round(rej_perc, 2)\n",
    "print (\"Rejected samples %:\", str(rej_perc) + '%')\n",
    "rejected_count = list(labels).count(-1)\n",
    "print (\"Rejected samples:\", rejected_count)\n",
    "print (\"Total samples:\", hits.shape[0])\n",
    "print (\"Clustered samples:\", hits.shape[0] - list(labels).count(-1), '\\n')\n",
    "\n",
    "print ('WITHOUT REJECTED SAMPLES:')\n",
    "labels_true_wr = labels_true[labels != -1]\n",
    "labels_wr = labels[labels != -1]\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels_true_wr, labels_wr))\n",
    "print((\"Completeness: %0.3f\" % metrics.completeness_score(labels_true_wr, labels_wr)), '\\n')\n",
    "\n",
    "plotdata.append[score]\n",
    "plotname.append[\"DBSCANmin_samp=3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = truth.particle_id.unique()[1::100]\n",
    "fig = plt.figure(figsize=(20,7))\n",
    "\n",
    "ax = fig.add_subplot(121,projection='3d')\n",
    "\n",
    "tracks_hit_ids = truth[truth['particle_id'].isin(tracks)]['hit_id'] # all hits in tracks\n",
    "clusters = clustering[clustering['hit_id'].isin(tracks_hit_ids)].track_id.unique() # all clusters containing the hits in tracks\n",
    "for cluster in clusters:\n",
    "    cluster_hit_ids = clustering[clustering['track_id'] == cluster]['hit_id'] # all hits in cluster\n",
    "    plot_hit_ids = list(set(tracks_hit_ids) & set(cluster_hit_ids))\n",
    "    t = hits[hits['hit_id'].isin(plot_hit_ids)][['x2', 'y2', 'z2']]\n",
    "    if cluster == -1:\n",
    "        ax.plot3D(t.z2, t.x2, t.y2, '.', ms=10, color='black')\n",
    "    else:\n",
    "        ax.plot3D(t.z2, t.x2, t.y2, '.-', ms=10)\n",
    "    \n",
    "ax.set_xlabel('z2')\n",
    "ax.set_ylabel('x2')\n",
    "ax.set_zlabel('y2')\n",
    "ax.set_title('Clustered Hits (Predicted Tracks)', y=-.15, size=20)\n",
    "\n",
    "ax2 = fig.add_subplot(122,projection='3d')\n",
    "for track in tracks:\n",
    "    hit_ids = truth[truth['particle_id'] == track]['hit_id']\n",
    "    t = hits[hits['hit_id'].isin(hit_ids)][['x2', 'y2', 'z2']]\n",
    "    t = arrange_track(t)\n",
    "    ax2.plot3D(t.z2, t.x2, t.y2, '.-', ms=10)\n",
    "    \n",
    "ax2.set_xlabel('z2')\n",
    "ax2.set_ylabel('x2')\n",
    "ax2.set_zlabel('y2')\n",
    "ax2.set_title('True Tracks', y=-.15, size=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = truth.particle_id.unique()[1::100]\n",
    "fig = plt.figure(figsize=(20,7))\n",
    "\n",
    "ax = fig.add_subplot(121,projection='3d')\n",
    "\n",
    "tracks_hit_ids = truth[truth['particle_id'].isin(tracks)]['hit_id'] # all hits in tracks\n",
    "clusters = clustering[clustering['hit_id'].isin(tracks_hit_ids)].track_id.unique() # all clusters containing the hits in tracks\n",
    "for cluster in clusters:\n",
    "    cluster_hit_ids = clustering[clustering['track_id'] == cluster]['hit_id'] # all hits in cluster\n",
    "    plot_hit_ids = list(set(tracks_hit_ids) & set(cluster_hit_ids))\n",
    "    t = hits[hits['hit_id'].isin(plot_hit_ids)][['x', 'y', 'z']]\n",
    "    if cluster == -1:\n",
    "        ax.plot3D(t.z, t.x, t.y, '.', ms=10, color='black')\n",
    "    else:\n",
    "        ax.plot3D(t.z, t.x, t.y, '.-', ms=10)\n",
    "    \n",
    "ax.set_xlabel('z (mm)')\n",
    "ax.set_ylabel('x (mm)')\n",
    "ax.set_zlabel('y (mm)')\n",
    "ax.set_title('Clustered Hits (Predicted Tracks)', y=-.15, size=20)\n",
    "\n",
    "ax2 = fig.add_subplot(122,projection='3d')\n",
    "for track in tracks:\n",
    "    hit_ids = truth[truth['particle_id'] == track]['hit_id']\n",
    "    t = hits[hits['hit_id'].isin(hit_ids)][['x', 'y', 'z']]\n",
    "    t = arrange_track(t)\n",
    "    ax2.plot3D(t.z, t.x, t.y, '.-', ms=10)\n",
    "    \n",
    "ax2.set_xlabel('z (mm)')\n",
    "ax2.set_ylabel('x (mm)')\n",
    "ax2.set_zlabel('y (mm)')\n",
    "ax2.set_title('True Tracks', y=-.15, size=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and here we have scaling and normalization with no coordinate transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hits[['x', 'y', 'z']]\n",
    "scaler = MaxAbsScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "normalizer = Normalizer(norm='l2').fit(X)\n",
    "X = normalizer.transform(X)\n",
    "\n",
    "eps = 0.0022\n",
    "min_samp = 3\n",
    "db = DBSCAN(eps=eps, min_samples=min_samp, metric='euclidean').fit(X)\n",
    "labels = db.labels_\n",
    "\n",
    "clustering = pd.DataFrame()\n",
    "clustering['hit_id'] = truth['hit_id']\n",
    "clustering['track_id'] = labels\n",
    "\n",
    "score = score_event(truth, clustering)\n",
    "print('track-ml custom metric score:', round(score, 4))\n",
    "\n",
    "labels_true = truth['particle_id']\n",
    "n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "\n",
    "print('\\nOTHER CLUSTERING RESULTS:')\n",
    "print('Estimated number of clusters: %d' % n_clusters)\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels_true, labels))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels_true, labels))\n",
    "print(\"Adjusted Rand Index: %0.3f\" % metrics.adjusted_rand_score(labels_true, labels))\n",
    "rej_perc = list(labels).count(-1) / float(hits.shape[0]) * 100\n",
    "rej_perc = round(rej_perc, 2)\n",
    "print (\"Rejected samples %:\", str(rej_perc) + '%')\n",
    "rejected_count = list(labels).count(-1)\n",
    "print (\"Rejected samples:\", rejected_count)\n",
    "print (\"Total samples:\", hits.shape[0])\n",
    "print (\"Clustered samples:\", hits.shape[0] - list(labels).count(-1), '\\n')\n",
    "\n",
    "print ('WITHOUT REJECTED SAMPLES:')\n",
    "labels_true_wr = labels_true[labels != -1]\n",
    "labels_wr = labels[labels != -1]\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels_true_wr, labels_wr))\n",
    "print((\"Completeness: %0.3f\" % metrics.completeness_score(labels_true_wr, labels_wr)), '\\n')\n",
    "\n",
    "plotdata.append[score]\n",
    "plotname.append[\"DBSCANscalingandnormalization\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = truth.particle_id.unique()[1::100]\n",
    "fig = plt.figure(figsize=(20,7))\n",
    "\n",
    "ax = fig.add_subplot(121,projection='3d')\n",
    "\n",
    "tracks_hit_ids = truth[truth['particle_id'].isin(tracks)]['hit_id'] # all hits in tracks\n",
    "clusters = clustering[clustering['hit_id'].isin(tracks_hit_ids)].track_id.unique() # all clusters containing the hits in tracks\n",
    "for cluster in clusters:\n",
    "    cluster_hit_ids = clustering[clustering['track_id'] == cluster]['hit_id'] # all hits in cluster\n",
    "    plot_hit_ids = list(set(tracks_hit_ids) & set(cluster_hit_ids))\n",
    "    t = hits[hits['hit_id'].isin(plot_hit_ids)][['x', 'y', 'z']]\n",
    "    if cluster == -1:\n",
    "        ax.plot3D(t.z, t.x, t.y, '.', ms=10, color='black')\n",
    "    else:\n",
    "        ax.plot3D(t.z, t.x, t.y, '.-', ms=10)\n",
    "    \n",
    "ax.set_xlabel('z (mm)')\n",
    "ax.set_ylabel('x (mm)')\n",
    "ax.set_zlabel('y (mm)')\n",
    "ax.set_title('Clustered Hits (Predicted Tracks)', y=-.15, size=20)\n",
    "\n",
    "ax2 = fig.add_subplot(122,projection='3d')\n",
    "for track in tracks:\n",
    "    hit_ids = truth[truth['particle_id'] == track]['hit_id']\n",
    "    t = hits[hits['hit_id'].isin(hit_ids)][['x', 'y', 'z']]\n",
    "    t = arrange_track(t)\n",
    "    ax2.plot3D(t.z, t.x, t.y, '.-', ms=10)\n",
    "    \n",
    "ax2.set_xlabel('z (mm)')\n",
    "ax2.set_ylabel('x (mm)')\n",
    "ax2.set_zlabel('y (mm)')\n",
    "ax2.set_title('True Tracks', y=-.15, size=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k means\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "random_state=42\n",
    "n_clusters=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hits[['x2', 'y2', 'z2']]\n",
    "scaler = StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "eps = 0.008\n",
    "min_samp = 1\n",
    "db = KMeans(n_clusters=n_clusters, random_state=random_state).fit(X)\n",
    "labels = db.labels_\n",
    "\n",
    "clustering = pd.DataFrame()\n",
    "clustering['hit_id'] = truth['hit_id']\n",
    "clustering['track_id'] = labels\n",
    "\n",
    "score = score_event(truth, clustering)\n",
    "print('track-ml custom metric score:', round(score, 4))\n",
    "\n",
    "labels_true = truth['particle_id']\n",
    "n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "\n",
    "print('\\nOTHER CLUSTERING RESULTS:')\n",
    "print('Estimated number of clusters: %d' % n_clusters)\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels_true, labels))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels_true, labels))\n",
    "print(\"Adjusted Rand Index: %0.3f\" % metrics.adjusted_rand_score(labels_true, labels))\n",
    "rej_perc = list(labels).count(-1) / float(hits.shape[0]) * 100\n",
    "rej_perc = round(rej_perc, 2)\n",
    "print (\"Rejected samples %:\", str(rej_perc) + '%')\n",
    "rejected_count = list(labels).count(-1)\n",
    "print (\"Rejected samples:\", rejected_count)\n",
    "print (\"Total samples:\", hits.shape[0])\n",
    "print (\"Clustered samples:\", hits.shape[0] - list(labels).count(-1))\n",
    "plotdata.append[score]\n",
    "plotname.append[\"kmeans\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = truth.particle_id.unique()[1::100]\n",
    "fig = plt.figure(figsize=(20,7))\n",
    "\n",
    "ax = fig.add_subplot(121,projection='3d')\n",
    "\n",
    "tracks_hit_ids = truth[truth['particle_id'].isin(tracks)]['hit_id'] # all hits in tracks\n",
    "clusters = clustering[clustering['hit_id'].isin(tracks_hit_ids)].track_id.unique() # all clusters containing the hits in tracks\n",
    "for cluster in clusters:\n",
    "    cluster_hit_ids = clustering[clustering['track_id'] == cluster]['hit_id'] # all hits in cluster\n",
    "    plot_hit_ids = list(set(tracks_hit_ids) & set(cluster_hit_ids))\n",
    "    t = hits[hits['hit_id'].isin(plot_hit_ids)][['x', 'y', 'z']]\n",
    "    if cluster == -1:\n",
    "        ax.plot3D(t.z, t.x, t.y, '.', ms=10, color='black')\n",
    "    else:\n",
    "        ax.plot3D(t.z, t.x, t.y, '.-', ms=10)\n",
    "    \n",
    "ax.set_xlabel('z (mm)')\n",
    "ax.set_ylabel('x (mm)')\n",
    "ax.set_zlabel('y (mm)')\n",
    "ax.set_title('Clustered Hits (Predicted Tracks)', y=-.15, size=20)\n",
    "\n",
    "ax2 = fig.add_subplot(122,projection='3d')\n",
    "for track in tracks:\n",
    "    hit_ids = truth[truth['particle_id'] == track]['hit_id']\n",
    "    t = hits[hits['hit_id'].isin(hit_ids)][['x', 'y', 'z']]\n",
    "    t = arrange_track(t)\n",
    "    ax2.plot3D(t.z, t.x, t.y, '.-', ms=10)\n",
    "    \n",
    "ax2.set_xlabel('z (mm)')\n",
    "ax2.set_ylabel('x (mm)')\n",
    "ax2.set_zlabel('y (mm)')\n",
    "ax2.set_title('True Tracks', y=-.15, size=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install cython\n",
    "#!conda install numpy scipy\n",
    "#!conda install scikit-learn\n",
    "#!pip install hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade git+https://github.com/scikit-learn-contrib/hdbscan.git#egg=hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "import hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hits[['x2', 'y2', 'z2']]\n",
    "scaler = StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "eps = 0.008\n",
    "min_samp = 1\n",
    "db = hdbscan.HDBSCAN(min_samples=1,min_cluster_size=7,cluster_selection_method='leaf',metric='braycurtis').fit(X)\n",
    "labels = db.labels_\n",
    "\n",
    "clustering = pd.DataFrame()\n",
    "clustering['hit_id'] = truth['hit_id']\n",
    "clustering['track_id'] = labels\n",
    "\n",
    "score = score_event(truth, clustering)\n",
    "print('track-ml custom metric score:', round(score, 4))\n",
    "\n",
    "labels_true = truth['particle_id']\n",
    "n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "\n",
    "print('\\nOTHER CLUSTERING RESULTS:')\n",
    "print('Estimated number of clusters: %d' % n_clusters)\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels_true, labels))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels_true, labels))\n",
    "print(\"Adjusted Rand Index: %0.3f\" % metrics.adjusted_rand_score(labels_true, labels))\n",
    "rej_perc = list(labels).count(-1) / float(hits.shape[0]) * 100\n",
    "rej_perc = round(rej_perc, 2)\n",
    "print (\"Rejected samples %:\", str(rej_perc) + '%')\n",
    "rejected_count = list(labels).count(-1)\n",
    "print (\"Rejected samples:\", rejected_count)\n",
    "print (\"Total samples:\", hits.shape[0])\n",
    "print (\"Clustered samples:\", hits.shape[0] - list(labels).count(-1))\n",
    "\n",
    "plotdata.append[score]\n",
    "plotname.append[\"hdbscan\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = truth.particle_id.unique()[1::100]\n",
    "fig = plt.figure(figsize=(20,7))\n",
    "\n",
    "ax = fig.add_subplot(121,projection='3d')\n",
    "\n",
    "tracks_hit_ids = truth[truth['particle_id'].isin(tracks)]['hit_id'] # all hits in tracks\n",
    "clusters = clustering[clustering['hit_id'].isin(tracks_hit_ids)].track_id.unique() # all clusters containing the hits in tracks\n",
    "for cluster in clusters:\n",
    "    cluster_hit_ids = clustering[clustering['track_id'] == cluster]['hit_id'] # all hits in cluster\n",
    "    plot_hit_ids = list(set(tracks_hit_ids) & set(cluster_hit_ids))\n",
    "    t = hits[hits['hit_id'].isin(plot_hit_ids)][['x', 'y', 'z']]\n",
    "    if cluster == -1:\n",
    "        ax.plot3D(t.z, t.x, t.y, '.', ms=10, color='black')\n",
    "    else:\n",
    "        ax.plot3D(t.z, t.x, t.y, '.-', ms=10)\n",
    "    \n",
    "ax.set_xlabel('z (mm)')\n",
    "ax.set_ylabel('x (mm)')\n",
    "ax.set_zlabel('y (mm)')\n",
    "ax.set_title('Clustered Hits (Predicted Tracks)', y=-.15, size=20)\n",
    "\n",
    "ax2 = fig.add_subplot(122,projection='3d')\n",
    "for track in tracks:\n",
    "    hit_ids = truth[truth['particle_id'] == track]['hit_id']\n",
    "    t = hits[hits['hit_id'].isin(hit_ids)][['x', 'y', 'z']]\n",
    "    t = arrange_track(t)\n",
    "    ax2.plot3D(t.z, t.x, t.y, '.-', ms=10)\n",
    "    \n",
    "ax2.set_xlabel('z (mm)')\n",
    "ax2.set_ylabel('x (mm)')\n",
    "ax2.set_zlabel('y (mm)')\n",
    "ax2.set_title('True Tracks', y=-.15, size=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BIRCH attempt?\n",
    "from sklearn.cluster import Birch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hits[['x2', 'y2', 'z2']]\n",
    "scaler = StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "eps = 0.008\n",
    "min_samp = 1\n",
    "db = Birch().fit(X)\n",
    "labels = db.labels_\n",
    "\n",
    "clustering = pd.DataFrame()\n",
    "clustering['hit_id'] = truth['hit_id']\n",
    "clustering['track_id'] = labels\n",
    "\n",
    "score = score_event(truth, clustering)\n",
    "print('track-ml custom metric score:', round(score, 4))\n",
    "\n",
    "labels_true = truth['particle_id']\n",
    "n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "\n",
    "print('\\nOTHER CLUSTERING RESULTS:')\n",
    "print('Estimated number of clusters: %d' % n_clusters)\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels_true, labels))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels_true, labels))\n",
    "print(\"Adjusted Rand Index: %0.3f\" % metrics.adjusted_rand_score(labels_true, labels))\n",
    "rej_perc = list(labels).count(-1) / float(hits.shape[0]) * 100\n",
    "rej_perc = round(rej_perc, 2)\n",
    "print (\"Rejected samples %:\", str(rej_perc) + '%')\n",
    "rejected_count = list(labels).count(-1)\n",
    "print (\"Rejected samples:\", rejected_count)\n",
    "print (\"Total samples:\", hits.shape[0])\n",
    "print (\"Clustered samples:\", hits.shape[0] - list(labels).count(-1))\n",
    "\n",
    "plotdata.append[score]\n",
    "plotname.append[\"Birch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = truth.particle_id.unique()[1::100]\n",
    "fig = plt.figure(figsize=(20,7))\n",
    "\n",
    "ax = fig.add_subplot(121,projection='3d')\n",
    "\n",
    "tracks_hit_ids = truth[truth['particle_id'].isin(tracks)]['hit_id'] # all hits in tracks\n",
    "clusters = clustering[clustering['hit_id'].isin(tracks_hit_ids)].track_id.unique() # all clusters containing the hits in tracks\n",
    "for cluster in clusters:\n",
    "    cluster_hit_ids = clustering[clustering['track_id'] == cluster]['hit_id'] # all hits in cluster\n",
    "    plot_hit_ids = list(set(tracks_hit_ids) & set(cluster_hit_ids))\n",
    "    t = hits[hits['hit_id'].isin(plot_hit_ids)][['x', 'y', 'z']]\n",
    "    if cluster == -1:\n",
    "        ax.plot3D(t.z, t.x, t.y, '.', ms=10, color='black')\n",
    "    else:\n",
    "        ax.plot3D(t.z, t.x, t.y, '.-', ms=10)\n",
    "    \n",
    "ax.set_xlabel('z (mm)')\n",
    "ax.set_ylabel('x (mm)')\n",
    "ax.set_zlabel('y (mm)')\n",
    "ax.set_title('Clustered Hits (Predicted Tracks)', y=-.15, size=20)\n",
    "\n",
    "ax2 = fig.add_subplot(122,projection='3d')\n",
    "for track in tracks:\n",
    "    hit_ids = truth[truth['particle_id'] == track]['hit_id']\n",
    "    t = hits[hits['hit_id'].isin(hit_ids)][['x', 'y', 'z']]\n",
    "    t = arrange_track(t)\n",
    "    ax2.plot3D(t.z, t.x, t.y, '.-', ms=10)\n",
    "    \n",
    "ax2.set_xlabel('z (mm)')\n",
    "ax2.set_ylabel('x (mm)')\n",
    "ax2.set_zlabel('y (mm)')\n",
    "ax2.set_title('True Tracks', y=-.15, size=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#minibatchkmeans attempt\n",
    "from sklearn.cluster import MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hits[['x2', 'y2', 'z2']]\n",
    "scaler = StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "eps = 0.008\n",
    "min_samp = 1\n",
    "db = MiniBatchKMeans(n_clusters=20).fit(X)\n",
    "labels = db.labels_\n",
    "\n",
    "clustering = pd.DataFrame()\n",
    "clustering['hit_id'] = truth['hit_id']\n",
    "clustering['track_id'] = labels\n",
    "\n",
    "score = score_event(truth, clustering)\n",
    "print('track-ml custom metric score:', round(score, 4))\n",
    "\n",
    "labels_true = truth['particle_id']\n",
    "n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "\n",
    "print('\\nOTHER CLUSTERING RESULTS:')\n",
    "print('Estimated number of clusters: %d' % n_clusters)\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels_true, labels))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels_true, labels))\n",
    "print(\"Adjusted Rand Index: %0.3f\" % metrics.adjusted_rand_score(labels_true, labels))\n",
    "rej_perc = list(labels).count(-1) / float(hits.shape[0]) * 100\n",
    "rej_perc = round(rej_perc, 2)\n",
    "print (\"Rejected samples %:\", str(rej_perc) + '%')\n",
    "rejected_count = list(labels).count(-1)\n",
    "print (\"Rejected samples:\", rejected_count)\n",
    "print (\"Total samples:\", hits.shape[0])\n",
    "print (\"Clustered samples:\", hits.shape[0] - list(labels).count(-1))\n",
    "\n",
    "plotdata.append[score]\n",
    "plotname.append[\"minibatchkmeans\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = truth.particle_id.unique()[1::100]\n",
    "fig = plt.figure(figsize=(20,7))\n",
    "\n",
    "ax = fig.add_subplot(121,projection='3d')\n",
    "\n",
    "tracks_hit_ids = truth[truth['particle_id'].isin(tracks)]['hit_id'] # all hits in tracks\n",
    "clusters = clustering[clustering['hit_id'].isin(tracks_hit_ids)].track_id.unique() # all clusters containing the hits in tracks\n",
    "for cluster in clusters:\n",
    "    cluster_hit_ids = clustering[clustering['track_id'] == cluster]['hit_id'] # all hits in cluster\n",
    "    plot_hit_ids = list(set(tracks_hit_ids) & set(cluster_hit_ids))\n",
    "    t = hits[hits['hit_id'].isin(plot_hit_ids)][['x', 'y', 'z']]\n",
    "    if cluster == -1:\n",
    "        ax.plot3D(t.z, t.x, t.y, '.', ms=10, color='black')\n",
    "    else:\n",
    "        ax.plot3D(t.z, t.x, t.y, '.-', ms=10)\n",
    "    \n",
    "ax.set_xlabel('z (mm)')\n",
    "ax.set_ylabel('x (mm)')\n",
    "ax.set_zlabel('y (mm)')\n",
    "ax.set_title('Clustered Hits (Predicted Tracks)', y=-.15, size=20)\n",
    "\n",
    "ax2 = fig.add_subplot(122,projection='3d')\n",
    "for track in tracks:\n",
    "    hit_ids = truth[truth['particle_id'] == track]['hit_id']\n",
    "    t = hits[hits['hit_id'].isin(hit_ids)][['x', 'y', 'z']]\n",
    "    t = arrange_track(t)\n",
    "    ax2.plot3D(t.z, t.x, t.y, '.-', ms=10)\n",
    "    \n",
    "ax2.set_xlabel('z (mm)')\n",
    "ax2.set_ylabel('x (mm)')\n",
    "ax2.set_zlabel('y (mm)')\n",
    "ax2.set_title('True Tracks', y=-.15, size=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GuassianMixture\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "X = hits[['x2', 'y2', 'z2']]\n",
    "scaler = StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "eps = 0.008\n",
    "min_samp = 1\n",
    "db = GaussianMixture().fit(X)\n",
    "labels = db.n_iter_\n",
    "\n",
    "clustering = pd.DataFrame()\n",
    "clustering['hit_id'] = truth['hit_id']\n",
    "clustering['track_id'] = labels\n",
    "\n",
    "score = score_event(truth, clustering)\n",
    "print('track-ml custom metric score:', round(score, 4))\n",
    "\n",
    "labels_true = truth['particle_id']\n",
    "n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "\n",
    "print('\\nOTHER CLUSTERING RESULTS:')\n",
    "print('Estimated number of clusters: %d' % n_clusters)\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels_true, labels))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels_true, labels))\n",
    "print(\"Adjusted Rand Index: %0.3f\" % metrics.adjusted_rand_score(labels_true, labels))\n",
    "rej_perc = list(labels).count(-1) / float(hits.shape[0]) * 100\n",
    "rej_perc = round(rej_perc, 2)\n",
    "print (\"Rejected samples %:\", str(rej_perc) + '%')\n",
    "rejected_count = list(labels).count(-1)\n",
    "print (\"Rejected samples:\", rejected_count)\n",
    "print (\"Total samples:\", hits.shape[0])\n",
    "print (\"Clustered samples:\", hits.shape[0] - list(labels).count(-1))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spectral cluster\n",
    "from sklearn.cluster import SpectralClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "X = hits[['x2', 'y2', 'z2']]\n",
    "scaler = StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "eps = 0.008\n",
    "min_samp = 1\n",
    "db = SpectralClustering().fit(X)\n",
    "labels = db.labels_\n",
    "\n",
    "clustering = pd.DataFrame()\n",
    "clustering['hit_id'] = truth['hit_id']\n",
    "clustering['track_id'] = labels\n",
    "\n",
    "score = score_event(truth, clustering)\n",
    "print('track-ml custom metric score:', round(score, 4))\n",
    "\n",
    "labels_true = truth['particle_id']\n",
    "n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "\n",
    "print('\\nOTHER CLUSTERING RESULTS:')\n",
    "print('Estimated number of clusters: %d' % n_clusters)\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels_true, labels))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels_true, labels))\n",
    "print(\"Adjusted Rand Index: %0.3f\" % metrics.adjusted_rand_score(labels_true, labels))\n",
    "rej_perc = list(labels).count(-1) / float(hits.shape[0]) * 100\n",
    "rej_perc = round(rej_perc, 2)\n",
    "print (\"Rejected samples %:\", str(rej_perc) + '%')\n",
    "rejected_count = list(labels).count(-1)\n",
    "print (\"Rejected samples:\", rejected_count)\n",
    "print (\"Total samples:\", hits.shape[0])\n",
    "print (\"Clustered samples:\", hits.shape[0] - list(labels).count(-1))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPtics\n",
    "from sklearn.cluster import OPTICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "X = hits[['x2', 'y2', 'z2']]\n",
    "scaler = StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "eps = 0.008\n",
    "min_samp = 1\n",
    "db = OPTICS().fit(X)\n",
    "labels = db.labels_\n",
    "\n",
    "clustering = pd.DataFrame()\n",
    "clustering['hit_id'] = truth['hit_id']\n",
    "clustering['track_id'] = labels\n",
    "\n",
    "score = score_event(truth, clustering)\n",
    "print('track-ml custom metric score:', round(score, 4))\n",
    "\n",
    "labels_true = truth['particle_id']\n",
    "n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "\n",
    "print('\\nOTHER CLUSTERING RESULTS:')\n",
    "print('Estimated number of clusters: %d' % n_clusters)\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels_true, labels))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels_true, labels))\n",
    "print(\"Adjusted Rand Index: %0.3f\" % metrics.adjusted_rand_score(labels_true, labels))\n",
    "rej_perc = list(labels).count(-1) / float(hits.shape[0]) * 100\n",
    "rej_perc = round(rej_perc, 2)\n",
    "print (\"Rejected samples %:\", str(rej_perc) + '%')\n",
    "rejected_count = list(labels).count(-1)\n",
    "print (\"Rejected samples:\", rejected_count)\n",
    "print (\"Total samples:\", hits.shape[0])\n",
    "print (\"Clustered samples:\", hits.shape[0] - list(labels).count(-1))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#neural network attempt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_new,X_trash,y_new, y_trash = train_test_split(X,truth[\"hit_id\"],test_size = 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "X = hits[['x2', 'y2', 'z2']]\n",
    "scaler = StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "\n",
    "eps = 0.008\n",
    "min_samp = 1\n",
    "db = MLPClassifier().fit(X_new, y_new)\n",
    "#labels = db.labels_\n",
    "\n",
    "clustering = pd.DataFrame()\n",
    "clustering['hit_id'] = truth['hit_id']\n",
    "#clustering['track_id'] = labels\n",
    "\n",
    "score = score_event(truth, clustering)\n",
    "print('track-ml custom metric score:', round(score, 4))\n",
    "\n",
    "labels_true = truth['particle_id']\n",
    "n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "\n",
    "print('\\nOTHER CLUSTERING RESULTS:')\n",
    "print('Estimated number of clusters: %d' % n_clusters)\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels_true, labels))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels_true, labels))\n",
    "print(\"Adjusted Rand Index: %0.3f\" % metrics.adjusted_rand_score(labels_true, labels))\n",
    "#rej_perc = list(labels).count(-1) / float(hits.shape[0]) * 100\n",
    "#rej_perc = round(rej_perc, 2)\n",
    "#print (\"Rejected samples %:\", str(rej_perc) + '%')\n",
    "#rejected_count = list(labels).count(-1)\n",
    "#print (\"Rejected samples:\", rejected_count)\n",
    "print (\"Total samples:\", hits.shape[0])\n",
    "#print (\"Clustered samples:\", hits.shape[0] - list(labels).count(-1))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modified HDBSCAN Trying to get best possible result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hits[['x2', 'y2', 'z2']]\n",
    "scaler = StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "eps = 0.008\n",
    "min_samp = 1\n",
    "db = hdbscan.HDBSCAN(min_samples=1,min_cluster_size=7,cluster_selection_method='leaf',metric='braycurtis').fit(X)\n",
    "labels = db.labels_\n",
    "\n",
    "clustering = pd.DataFrame()\n",
    "clustering['hit_id'] = truth['hit_id']\n",
    "clustering['track_id'] = labels\n",
    "\n",
    "score = score_event(truth, clustering)\n",
    "print('track-ml custom metric score:', round(score, 4))\n",
    "\n",
    "labels_true = truth['particle_id']\n",
    "n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "\n",
    "print('\\nOTHER CLUSTERING RESULTS:')\n",
    "print('Estimated number of clusters: %d' % n_clusters)\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels_true, labels))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels_true, labels))\n",
    "print(\"Adjusted Rand Index: %0.3f\" % metrics.adjusted_rand_score(labels_true, labels))\n",
    "rej_perc = list(labels).count(-1) / float(hits.shape[0]) * 100\n",
    "rej_perc = round(rej_perc, 2)\n",
    "print (\"Rejected samples %:\", str(rej_perc) + '%')\n",
    "rejected_count = list(labels).count(-1)\n",
    "print (\"Rejected samples:\", rejected_count)\n",
    "print (\"Total samples:\", hits.shape[0])\n",
    "print (\"Clustered samples:\", hits.shape[0] - list(labels).count(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = truth.particle_id.unique()[1::100]\n",
    "fig = plt.figure(figsize=(20,7))\n",
    "\n",
    "ax = fig.add_subplot(121,projection='3d')\n",
    "\n",
    "tracks_hit_ids = truth[truth['particle_id'].isin(tracks)]['hit_id'] # all hits in tracks\n",
    "clusters = clustering[clustering['hit_id'].isin(tracks_hit_ids)].track_id.unique() # all clusters containing the hits in tracks\n",
    "for cluster in clusters:\n",
    "    cluster_hit_ids = clustering[clustering['track_id'] == cluster]['hit_id'] # all hits in cluster\n",
    "    plot_hit_ids = list(set(tracks_hit_ids) & set(cluster_hit_ids))\n",
    "    t = hits[hits['hit_id'].isin(plot_hit_ids)][['x2', 'y2', 'z2']]\n",
    "    if cluster == -1:\n",
    "        ax.plot3D(t.z2, t.x2, t.y2, '.', ms=10, color='black')\n",
    "    else:\n",
    "        ax.plot3D(t.z2, t.x2, t.y2, '.-', ms=10)\n",
    "    \n",
    "ax.set_xlabel('z2')\n",
    "ax.set_ylabel('x2')\n",
    "ax.set_zlabel('y2')\n",
    "ax.set_title('Clustered Hits (Predicted Tracks)', y=-.15, size=20)\n",
    "\n",
    "ax2 = fig.add_subplot(122,projection='3d')\n",
    "for track in tracks:\n",
    "    hit_ids = truth[truth['particle_id'] == track]['hit_id']\n",
    "    t = hits[hits['hit_id'].isin(hit_ids)][['x2', 'y2', 'z2']]\n",
    "    t = arrange_track(t)\n",
    "    ax2.plot3D(t.z2, t.x2, t.y2, '.-', ms=10)\n",
    "    \n",
    "ax2.set_xlabel('z2')\n",
    "ax2.set_ylabel('x2')\n",
    "ax2.set_zlabel('y2')\n",
    "ax2.set_title('True Tracks', y=-.15, size=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = truth.particle_id.unique()[1::100]\n",
    "fig = plt.figure(figsize=(20,7))\n",
    "\n",
    "ax = fig.add_subplot(121,projection='3d')\n",
    "\n",
    "tracks_hit_ids = truth[truth['particle_id'].isin(tracks)]['hit_id'] # all hits in tracks\n",
    "clusters = clustering[clustering['hit_id'].isin(tracks_hit_ids)].track_id.unique() # all clusters containing the hits in tracks\n",
    "for cluster in clusters:\n",
    "    cluster_hit_ids = clustering[clustering['track_id'] == cluster]['hit_id'] # all hits in cluster\n",
    "    plot_hit_ids = list(set(tracks_hit_ids) & set(cluster_hit_ids))\n",
    "    t = hits[hits['hit_id'].isin(plot_hit_ids)][['x', 'y', 'z']]\n",
    "    if cluster == -1:\n",
    "        ax.plot3D(t.z, t.x, t.y, '.', ms=10, color='black')\n",
    "    else:\n",
    "        ax.plot3D(t.z, t.x, t.y, '.-', ms=10)\n",
    "    \n",
    "ax.set_xlabel('z (mm)')\n",
    "ax.set_ylabel('x (mm)')\n",
    "ax.set_zlabel('y (mm)')\n",
    "ax.set_title('Clustered Hits (Predicted Tracks)', y=-.15, size=20)\n",
    "\n",
    "ax2 = fig.add_subplot(122,projection='3d')\n",
    "for track in tracks:\n",
    "    hit_ids = truth[truth['particle_id'] == track]['hit_id']\n",
    "    t = hits[hits['hit_id'].isin(hit_ids)][['x', 'y', 'z']]\n",
    "    t = arrange_track(t)\n",
    "    ax2.plot3D(t.z, t.x, t.y, '.-', ms=10)\n",
    "    \n",
    "ax2.set_xlabel('z (mm)')\n",
    "ax2.set_ylabel('x (mm)')\n",
    "ax2.set_zlabel('y (mm)')\n",
    "ax2.set_title('True Tracks', y=-.15, size=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot of models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(plotdata)\n",
    "print(plotnames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
